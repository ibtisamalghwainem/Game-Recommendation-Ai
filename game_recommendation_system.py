# -*- coding: utf-8 -*-
"""Game_Recommendation_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hdk-SfAuHCiIVOAI38fPvF6qlucRicj9

# **Game Recommendation System**

# **DATA Initialization**
"""

# Reproducibility
import random, numpy as _np
random.seed(42)
_np.random.seed(42)
import warnings
warnings.filterwarnings('ignore')

"""## **Data Inspection 🔍**"""

from google.colab import files
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN, KMeans
from sklearn.metrics import davies_bouldin_score, silhouette_score

# نقرأ الملف
df = pd.read_csv("/content/steamgames_100k_rows.csv")

# نعرض أول 5 أسطر للتأكد
# NOTE: Sampling a fraction of the data for prototyping. Remove for full run.
df = df.sample(frac=0.2, random_state=42)

df.head().T

print(df.columns)

print('🧾INFO:')
df.info()

print('\n📐SHAPE:',df.shape)

print('\n🚫NULLS:')
print(df.isna().sum())

print('\n❗❗DUPLICATES:',df.duplicated().sum())

"""## **Data Cleaning 🧹**"""

df.drop_duplicates(inplace=True)
print(df.shape)

# Replace missing values in 'Hours' with the mean
df['Hours'].fillna(df['Hours'].mean(), inplace=True)

# Replace missing values in 'Behavior' with the mode
df['Behavior'].fillna(df['Behavior'].mode()[0], inplace=True)

# Now you can check for null values again to confirm they are all gone
print(df.isnull().sum())

print('🧾INFO:')
df.info()
print('\n🔍HEAD:')
df.head()

# checking for unwanted values (any other behaviors get dropped)
df = df[df["Behavior"].isin(["play", "purchase"])].copy()
# object to string
df["GameName"] = df["GameName"].astype("string")
df["Behavior"] = df["Behavior"].astype("string")
# Convert UserID to a nullable integer type to handle potential nulls
df['UserID'] = df['UserID'].astype('Int64')
# Convert Categories and Genres to the 'category' data type for memory efficiency
df['Categories'] = df['Categories'].astype('category')
df['Genres'] = df['Genres'].astype('category')
# Check the DataFrame info after the changes
print('🧾New INFO:')
df.info()

"""## **Feature Engineering 🛠️**"""

# total playtime per user
playtime = (df[df["Behavior"]=="play"].groupby("UserID", observed=True)["Hours"].sum().rename("total_play_hours"))

# total purchases per user
purchases = (df[df["Behavior"]=="purchase"].groupby("UserID", observed=True).size().rename("purchase_count"))

# total interactions (play+purchase) per user
interactions = (df.groupby("UserID", observed=True).size().rename("total_interactions"))

# average playtime per game for each user
avg_play = (df[df["Behavior"]=="play"].groupby("UserID", observed=True)["Hours"].mean().rename("avg_playtime"))

# Calculate the number of unique genres and categories for each user
unique_genres = df.groupby("UserID", observed=True)["Genres"].nunique().rename("unique_genres")
unique_categories = df.groupby("UserID", observed=True)["Categories"].nunique().rename("unique_categories")

# aggregate all stats
stats = (pd.concat([playtime, purchases, interactions, avg_play, unique_genres, unique_categories], axis=1)
         .fillna({"total_play_hours":0, "purchase_count":0, "avg_playtime":0, "unique_genres":0, "unique_categories":0})
         .reset_index())

# purchase ratio = purchases/total interactions
stats["purchase_ratio"] = (stats["purchase_count"] / stats["total_interactions"].replace(0, np.nan)).fillna(0)

print('Calculating and Aggregating to new useful features 🛠️:\n')
print(stats.head())

"""## **Encoding 🔢**"""

# filtering top games only
top_games = (df["GameName"].value_counts().nlargest(100)).index
df_top = df[df["GameName"].isin(top_games)].copy()

# we only care if the user interacted (regardless played or purchased)
df_top["interacted"] = 1

# One-hot encoding (user × game matrix)
bin_encoder = (df_top.drop_duplicates(["UserID","GameName"]).pivot(index="UserID", columns="GameName", values="interacted").fillna(0).astype("uint8"))
print('🔢One-Hot encoded matrix:')
print('* 1 indicates the user interacted with the game (wether played or purchased)')
print(bin_encoder.head())

# add the top games binary columns
user_features = stats.merge(bin_encoder, on="UserID", how="left").fillna(0)
print('\n🔗Merging the one-hot encoded matrix with the stats:')
print(user_features.head())

# encoding behavior to 1/0
behavior_encoder = LabelEncoder()
encoded_values1 = behavior_encoder.fit_transform(df_top["Behavior"])
encoded_behavior_df = pd.DataFrame({
    "Behavior": behavior_encoder.classes_,
    "Code": range(len(behavior_encoder.classes_))
})
print('#️⃣The code to each behavior:')
print(encoded_behavior_df)
print('\n🧮The number of elements in each behavior:')
print(df_top["Behavior"].value_counts())
print()

plt.figure(figsize=(5, 3))
pd.Series(encoded_values1).value_counts().sort_index().plot(kind='bar', title="Behavior Distribution", color='lightblue')
plt.xlabel("Class (0 = first category, 1 = second category)")
plt.ylabel("Count")
plt.show()

# encoding game names to numbers
game_encoder = LabelEncoder()
encoded_values2 = game_encoder.fit_transform(df_top["GameName"].unique())
encoded_games_df = pd.DataFrame({
    "GameName": game_encoder.classes_,
    "Code": encoded_values2
})
print('\n#️⃣The code to each game:')
print(encoded_games_df)

"""## **Normalization 📏**"""

# normalization
dense_cols = ["total_play_hours","purchase_count","purchase_ratio","avg_playtime"]
X_dense = user_features[dense_cols].copy()
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_dense)
print('Numeric Measures normalized ✅')
pd.DataFrame(X_scaled, columns=dense_cols).describe().loc[['mean','std']]

"""## **Visualization 📊**"""

# histogram showing the avg hours spended on each of the 100 top games

avg_playtime_per_game = (
    df_top[df_top["Behavior"] == "play"]
    .groupby("GameName", observed=True)["Hours"]
    .mean()
    .sort_values(ascending=False)
)

top20_avg = avg_playtime_per_game.head(20)

plt.figure(figsize=(12,6))
top20_avg.plot(kind="bar", color="lightseagreen", edgecolor="black")
plt.title("Top 20 Games by Average Playtime")
plt.ylabel("Average Hours")
plt.xlabel("GameName")
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""# **Unsupervised Clustering ( K-Means )**

## **Finding Number of Clusters 🧩**
"""

# num of clusters (elbow + silhouette score)
inertias = []
sil_scores = []

for k in range(2, 11):
    km = KMeans(n_clusters=k, n_init="auto", random_state=42)
    km.fit(X_scaled)
    inertias.append(km.inertia_)
    sil_scores.append(silhouette_score(X_scaled, km.labels_))

plt.figure(figsize=(5, 3))
plt.plot(range(2, 11), inertias, marker="o")
plt.xlabel("K"); plt.ylabel("Inertia"); plt.title("Elbow")
plt.show()

print()

plt.figure(figsize=(5, 3))
plt.plot(range(2, 11), sil_scores, marker="o")
plt.xlabel("K"); plt.ylabel("Silhouette"); plt.title("Silhouette")
plt.show()

"""## **KMeans Clustering ⚙️**"""

# kmeans
best_k = 4
kmeans = KMeans(n_clusters=best_k, n_init="auto", random_state=42)
labels_km = kmeans.fit_predict(X_scaled)
user_features["cluster_km"] = labels_km
print('KMeans Clustering applied with k=4 ✅')
print("✨KMeans silhouette:", silhouette_score(X_scaled, labels_km))
print("📐KMeans DB index:", davies_bouldin_score(X_scaled, labels_km))

"""## **DBSCAN Clustering 🌌**"""

# dbscan
from sklearn.cluster import DBSCAN
for eps in [0.3, 0.5, 0.7, 1.0]:
    db = DBSCAN(eps=eps, min_samples=10)
    db_labels = db.fit_predict(X_scaled)
    n_clusters = len(set(db_labels)) - (1 if -1 in db_labels else 0)
    n_noise = np.sum(db_labels == -1)
    if n_clusters > 1:
        sil = silhouette_score(X_scaled[db_labels!=-1], db_labels[db_labels!=-1])
    else:
        sil = np.nan
    print(f"eps={eps}: clusters={n_clusters}, noise={n_noise}, silhouette={sil}")

# choose eps that gives reasonable clusters and low noise
db_labels = DBSCAN(eps=0.7, min_samples=10).fit_predict(X_scaled)
user_features["cluster_db"] = db_labels
print('DBSCAN Clustering applied with eps=0.7 ✅')
print('\n⚖️Comparing clusters of km to db:')
print(user_features["cluster_km"].value_counts())
print()
print(user_features["cluster_db"].value_counts())

# showing the cluster each row belongs to (-1 is noise)
print('\n🧩Showing the cluster each row belongs to:')
print(user_features.head())

"""## **Visualizing Clusters 🧮**"""

# Visualize KMeans clusters
plt.figure(figsize=(8, 4))
sns.scatterplot(x=X_scaled[:, 0], y=X_scaled[:, 1], hue=user_features['cluster_km'], palette='viridis', legend='full')
plt.title('KMeans Clustering')
plt.xlabel('Scaled total_play_hours')
plt.ylabel('Scaled purchase_count')
plt.show()

print()

# Visualize DBSCAN clusters
plt.figure(figsize=(8, 4))
sns.scatterplot(x=X_scaled[:, 0], y=X_scaled[:, 1], hue=user_features['cluster_db'], palette='viridis', legend='full')
plt.title('DBSCAN Clustering')
plt.xlabel('Scaled total_play_hours')
plt.ylabel('Scaled purchase_count')
plt.show()

"""## **Outliers Detection 🚨**"""

# outliers detection


hours_play = df[df["Behavior"]=="play"]["Hours"]
Q1, Q3 = np.percentile(hours_play, [25, 75])
IQR = Q3 - Q1
lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR

outliers = hours_play[(hours_play < lower) | (hours_play > upper)]

print(f"🚨 Outliers detected: {len(outliers)} values")
print(f"Lower Bound={lower:.2f}, Upper Bound={upper:.2f}")
print(outliers.head())

plt.figure(figsize=(8,5))
sns.boxplot(x=hours_play, color="lightcoral")
plt.title("Outliers Detection in Play Hours 🚨")
plt.show()

"""## **Cluster Profiling 🎯**"""

features = ["total_play_hours", "purchase_count", "total_interactions", "avg_playtime", "purchase_ratio"]
X = stats[features]

kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
stats["Cluster"] = kmeans.fit_predict(X)

cluster_profile = stats.groupby("Cluster")[features].mean().round(2)
print("📊 Cluster Profiling:")
print(cluster_profile)

plt.figure(figsize=(8,6))
sns.scatterplot(data=stats, x="total_play_hours", y="avg_playtime", hue="Cluster", palette="Set2", alpha=0.7)
plt.title("Cluster Profiling of Users")
plt.show()

"""# **Supervised Prediction**

## **Data Splitting for Supervised Learning**
"""

from sklearn.model_selection import train_test_split

final_df = stats.merge(df[['UserID', 'Behavior']], on='UserID', how='left')

X = final_df.drop(columns=['UserID', 'Behavior'], errors='ignore')
y = final_df['Behavior']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"عدد صفوف بيانات التدريب (X_train): {X_train.shape[0]}")
print(f"عدد صفوف بيانات الاختبار (X_test): {X_test.shape[0]}")

"""## **Model training and comparison**"""

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# تهيئة النماذج
log_reg = LogisticRegression(random_state=42, solver='liblinear')
rf_clf = RandomForestClassifier(random_state=42, n_estimators=100)

# تدريب نموذج الانحدار اللوجستي
print("Training Logistic Regression model...")
log_reg.fit(X_train, y_train)
print("✅ تدريب نموذج Logistic Regression اكتمل.")

# تدريب نموذج الغابة العشوائية
print("\nTraining Random Forest model...")
rf_clf.fit(X_train, y_train)
print("✅ تدريب نموذج Random Forest اكتمل.")

"""## **Model Evaluation and Comparison**"""

from sklearn.metrics import classification_report, confusion_matrix

# الحصول على تنبؤات من نموذج الانحدار اللوجستي
y_pred_log_reg = log_reg.predict(X_test)

# الحصول على تنبؤات من نموذج الغابة العشوائية
y_pred_rf = rf_clf.predict(X_test)

# --- تقييم نموذج الانحدار اللوجستي ---
print("✅ تقييم نموذج الانحدار اللوجستي (Logistic Regression):")
print("\n- تقرير التصنيف:")
print(classification_report(y_test, y_pred_log_reg))
print("\n- مصفوفة الالتباس:")
print(confusion_matrix(y_test, y_pred_log_reg))

# --- تقييم نموذج الغابة العشوائية ---
print("\n\n✅ تقييم نموذج الغابة العشوائية (Random Forest):")
print("\n- تقرير التصنيف:")
print(classification_report(y_test, y_pred_rf))
print("\n- مصفوفة الالتباس:")
print(confusion_matrix(y_test, y_pred_rf))

"""#  **Final User Interface (Gradio)**


"""

import gradio as gr
from sklearn.cluster import KMeans

# --- 1. إعداد البيانات وتدريب النماذج ---
print("✅ جارٍ إعداد البيانات وتدريب النماذج...")

# أ. تحميل البيانات
file_path = 'steamgames_100k_rows.csv'
try:
    df = pd.read_csv(file_path)

    has_genres = 'Genres' in df.columns
    has_categories = 'Categories' in df.columns

    if not has_genres or not has_categories:
        print("⚠️ ملاحظة: ملف CSV الحالي لا يحتوي على أعمدة 'Genres' و 'Categories'.")
        print("سيتم عرض 'Not Available' في التوصيات.")

except FileNotFoundError:
    print("❌ خطأ: لم يتم العثور على الملف. تأكد من أن الملف تم تحميله مباشرة إلى Colab.")
    exit()

# أخذ عينة من البيانات لسرعة المعالجة
# NOTE: Sampling a fraction of the data for prototyping. Remove for full run.
df = df.sample(frac=0.2, random_state=42)

# ب. بناء الخصائص السلوكية للمستخدمين
try:
    playtime = df[df["Behavior"] == "play"].groupby("UserID", observed=True)["Hours"].sum().rename("total_play_hours")
    purchases = df[df["Behavior"] == "purchase"].groupby("UserID", observed=True).size().rename("purchase_count")
    interactions = df.groupby("UserID", observed=True).size().rename("total_interactions")
    avg_play = df[df["Behavior"] == "play"].groupby("UserID", observed=True)["Hours"].mean().rename("avg_playtime")
    stats = pd.concat([playtime, purchases, interactions, avg_play], axis=1).fillna(0).reset_index()
    stats["purchase_ratio"] = (stats["purchase_count"] / stats["total_interactions"].replace(0, np.nan)).fillna(0)
except Exception as e:
    print(f"❌ خطأ: فشل في بناء الخصائص السلوكية. الخطأ: {e}")
    exit()

if stats.empty:
    print("❌ خطأ: لا يوجد أي مستخدمين صالحين في العينة التي تم تحليلها.")
    exit()

# ج. التجميع (Clustering)
try:
    best_k = 4
    dense_cols = ["total_play_hours", "purchase_count", "purchase_ratio", "avg_playtime"]
    X_dense = stats[dense_cols].copy()
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_dense)
    kmeans = KMeans(n_clusters=best_k, n_init="auto", random_state=42)
    stats['Cluster'] = kmeans.fit_predict(X_scaled)
except Exception as e:
    print(f"❌ خطأ: فشل في عملية التجميع. الخطأ: {e}")
    exit()

# د. التنبؤ (Prediction)
try:
    log_reg = LogisticRegression(random_state=42, solver='liblinear')
    X = stats.drop(columns=['UserID', 'Cluster'])
    y = stats['purchase_ratio'].apply(lambda x: 1 if x > 0 else 0)
    log_reg.fit(X, y)
except Exception as e:
    print(f"❌ خطأ: فشل في تدريب نموذج التنبؤ. الخطاء: {e}")
    exit()

print("✅ تم الإعداد بنجاح. الواجهة جاهزة للتشغيل.")

# --- 2. تعريف الدوال للواجهة التفاعلية ---

def user_profile(uid):
    user_data = stats[stats['UserID'] == uid]
    if user_data.empty:
        return f"**Error:** User {uid} not found."

    cluster_name_map = {0: "اللاعبون المحترفون (Pro Gamers)", 1: "المستخدمون العاديون (Casuals)", 2: "المشترون (Buyers)", 3: "لاعبو الألعاب المجانية (Free-to-Play)"}
    cluster_name = cluster_name_map.get(user_data['Cluster'].iloc[0], "غير معروفة (Unknown)")

    return f"""
<div style='color: #4CAF50; font-size: 1.2em; font-weight: bold;'>👤 User Profile</div>

- **User ID**: {int(uid)}
- **Total Play Hours**: {int(user_data['total_play_hours'].iloc[0])} hours
- **Purchases**: {int(user_data['purchase_count'].iloc[0])}
- **User Type**: {cluster_name}
    """

def purchase_prediction(uid):
    user_data = stats[stats['UserID'] == uid]
    if user_data.empty:
        return f"**Error:** User {uid} not found."

    user_features = user_data.drop(columns=['UserID', 'Cluster'])
    purchase_prob = log_reg.predict_proba(user_features)[0][1]

    prediction_text = "Highly Likely to Buy" if purchase_prob > 0.5 else "Unlikely to Buy"
    purchase_prob_percent = round(purchase_prob * 100, 2)

    return f"""
<div style='color: #4CAF50; font-size: 1.2em; font-weight: bold;'>🔮 Purchase Prediction</div>

- **Prediction**: {prediction_text}
- **Probability**: {purchase_prob_percent}%
    """

def get_recommendations(uid):
    user_data = stats[stats['UserID'] == uid]
    if user_data.empty:
        return "No data found for this user."

    interacted_games = df[df['UserID'] == uid]['GameName'].unique()
    all_games = df['GameName'].unique()
    non_interacted_games = all_games[~np.isin(all_games, interacted_games)]

    if len(non_interacted_games) == 0:
        return "This user has interacted with all available games."

    user_features = user_data.drop(columns=['UserID', 'Cluster'])
    purchase_prob = log_reg.predict_proba(user_features)[0][1]

    recs_df = pd.DataFrame({'GameName': non_interacted_games, 'PurchaseProbability': [purchase_prob] * len(non_interacted_games)})
    recs_df = recs_df.sort_values(by='PurchaseProbability', ascending=False)

    output_html = ""
    cluster_name_map = {0: "Pro Gamers", 1: "Casuals", 2: "Buyers", 3: "Free-to-Play"}
    cluster_name = cluster_name_map.get(user_data['Cluster'].iloc[0], "Unknown")

    has_genres = 'Genres' in df.columns
    has_categories = 'Categories' in df.columns

    for index, row in recs_df.head(5).iterrows():
        prob = row['PurchaseProbability']
        prob_color = "#55d852" if prob > 0.5 else "#F44336"

        game_info = df[df['GameName'] == row['GameName']].iloc[0]
        game_genres = game_info['Genres'] if has_genres else "Not Available"
        game_categories = game_info['Categories'] if has_categories else "Not Available"

        output_html += f"""
        <div class="rec-card" style="
            display: flex;
            align-items: center;
            background-color: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            box-shadow: 2px 2px 0px #d0d0d0;
            padding: 15px;
            margin-bottom: 15px;
            transition: transform 0.2s;
        ">
            <div class="game-cover" style="
                width: 80px;
                height: 80px;
                background-color: #ddd;
                border: 2px solid #333;
                box-shadow: 3px 3px 0px #999;
                border-radius: 8px;
                margin-right: 15px;
                display: flex;
                align-items: center;
                justify-content: center;
                font-size: 40px;
                color: #aaa;
            ">🎮</div>
            <div style="flex-grow: 1;">
                <h3 style="color: #4CAF50; margin: 0 0 5px 0; font-size: 1.1em; font-weight: 600;">{row['GameName']}</h3>
                <p style="color: #666; font-size: 0.9em; margin: 0 0 8px 0;">
                    <span style="color: #999;">🕹️ Genre:</span> {game_genres}
                    <br>
                    <span style="color: #999;">👥 Style:</span> {game_categories}
                </p>
                <div class="progress-container" style="
                    background-color: #ecf0f1;
                    border-radius: 5px;
                    height: 10px;
                    width: 100%;
                    overflow: hidden;
                ">
                    <div class="progress-bar" style="
                        background-color: {prob_color};
                        height: 100%;
                        width: {round(prob * 100)}%;
                    "></div>
                </div>
                <p style="color: #333; margin: 5px 0 0 0; font-size: 0.8em;">**Probability:** <span style="font-weight: bold; color: {prob_color};">{round(prob * 100, 2)}%</span></p>
            </div>
        </div>
        """
    return f"""
    <div style='color: #2c3e50; font-size: 1.5em; font-weight: bold; margin-bottom: 15px;'>🎯 Recommended Games 🎯</h3></div>
    <div>{output_html}</div>
    """

# --- 3. بناء الواجهة باستخدام الدوال المدمجة ---
def run_all(uid):
    profile = user_profile(uid)
    pred = purchase_prediction(uid)
    recs = get_recommendations(uid)

    return profile, pred, recs

poppins_font_url = "https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&display=swap"
pixel_font_url = "https://fonts.googleapis.com/css2?family=Press+Start+2P&display=swap"

custom_css = f"""
    @import url('{poppins_font_url}');
    @import url('{pixel_font_url}');

    body {{
        background-color: #f0f2f5;
        color: #2c3e50;
        font-family: 'Poppins', sans-serif;
    }}
    .gr-button.primary {{
        background-color: #34495e;
        border: 2px solid #2c3e50;
        color: #fff;
        transition: all 0.2s;
        cursor: pointer;
    }}
    .gr-button.primary:hover {{
        background-color: #2c3e50;
        border-color: #34495e;
        transform: scale(1.05);
    }}
    .gradio-container {{
        background: #f7f7f7;
        border-radius: 15px;
        box-shadow: 0 10px 25px rgba(0,0,0,0.1);
        padding: 20px;
    }}
    .pixel-header {{
        position: relative;
        background-color: #e6f0f5;
        padding: 30px;
        text-align: center;
        border-radius: 15px 15px 0 0;
        overflow: hidden;
        border-bottom: 3px solid #ccc;
    }}
    .pixel-header::before {{
        content: '';
        position: absolute;
        bottom: 0;
        left: 0;
        width: 100%;
        height: 10px;
        background-color: #d8d8d8;
        z-index: 1;
    }}
    .title-text {{
        font-family: 'Press Start 2P', cursive;
        color: #34495e;
        font-size: 2.5em;
        text-align: center;
        margin-bottom: 0;
        z-index: 3;
        position: relative;
        text-shadow: 2px 2px 0px #bdc3c7;
    }}
    .tabs {{
        background-color: #ecf0f1;
        border-radius: 12px;
        padding: 5px;
        border: 1px solid #bdc3c7;
    }}
    .tab-nav button {{
        background-color: transparent !important;
        border: none !important;
        color: #7f8c8d !important;
        font-family: 'Poppins', sans-serif;
        font-weight: 600;
        transition: transform 0.2s, background-color 0.2s;
    }}
    .tab-nav button:hover {{
        transform: translateY(-2px);
    }}
    .tab-nav button.selected {{
        background-color: #34495e !important;
        border-radius: 8px !important;
        color: #fff !important;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        transform: scale(1.05);
    }}
    .rec-card {{
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        box-shadow: 2px 2px 0px #d0d0d0;
        padding: 15px;
        margin-bottom: 15px;
        transition: transform 0.2s;
    }}
    .rec-card:hover {{
        transform: translateY(-5px);
        box-shadow: 5px 5px 0px #a0a0a0;
    }}
    .progress-container {{
        background-color: #ecf0f1;
        border-radius: 5px;
        height: 10px;
        width: 100%;
        overflow: hidden;
    }}
    .progress-bar {{
        background-color: #34495e;
        height: 100%;
        width: 0%;
    }}
"""

with gr.Blocks(theme=gr.themes.Monochrome(), css=custom_css) as demo:
    with gr.Row():
        with gr.Column():
            gr.HTML("""
                <div class="pixel-header">
                    <h1 class="title-text">ML GAME RECOMMENDATION SYSTEM</h1>
                </div>
            """)

    gr.Markdown("A professional and modern interface to get personalized game recommendations.", elem_classes="emoji-bg")

    valid_uids = [int(u) for u in stats['UserID'].tolist()]
    user_id_input = gr.Dropdown(
        label="Select User ID",
        choices=valid_uids,
        value=valid_uids[0] if valid_uids else None
    )

    run_btn = gr.Button("Get Recommendations", elem_classes="primary")

    with gr.Tabs() as tabs:
        with gr.Tab("👤 User Profile"):
            profile_out = gr.Markdown()

        with gr.Tab("🔮 Prediction"):
            prediction_out = gr.Markdown()

        with gr.Tab("🎯 Recommendations"):
            rec_out = gr.HTML()

    run_btn.click(fn=run_all, inputs=user_id_input, outputs=[profile_out, prediction_out, rec_out])

demo.launch(share=True)